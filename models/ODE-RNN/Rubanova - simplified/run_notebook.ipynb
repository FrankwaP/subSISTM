{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent ODEs for Irregularly-Sampled Time Series\n",
    "#### Author: Yulia Rubanova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import pandas as pd\n",
    "from random import SystemRandom\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils\n",
    "from utils import compute_loss_all_batches\n",
    "\n",
    "from ode_rnn import *\n",
    "from ode_func import ODEFunc\n",
    "from diffeq_solver import DiffeqSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_NOISY_DATA = False\n",
    "USE_MIXED_EFFECT = False\n",
    "RANDOM_TIME = True\n",
    "RE = 'Mixed' if USE_MIXED_EFFECT else 'Fixed'\n",
    "Time = 'Random time' if RANDOM_TIME else 'Regular time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "CSV_FILE = \"../../../data/synthetic_bph_1/Simulations regular time/simulation1.csv\"\n",
    "CSV_Dtest = \"../../../data/synthetic_bph_1/Simulations regular time/01_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(CSV_FILE, sep=\";\", decimal=\",\")\n",
    "dtest = pd.read_csv(CSV_Dtest, sep=\";\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']\n",
      "['y_fixed_obs']\n"
     ]
    }
   ],
   "source": [
    "x_labels = [\n",
    "    c for c in data.columns if c.startswith(\"x\") and (((\"_\" in c) is USE_NOISY_DATA and ('obs' in c) is USE_NOISY_DATA))\n",
    "]\n",
    "if 'x8' not in x_labels:\n",
    "    x_labels.append('x8')\n",
    "#assert len(x_labels) == 8\n",
    "\n",
    "y_labels = [\n",
    "    c\n",
    "    for c in data.columns\n",
    "    if c.startswith(\"y\")\n",
    "    and ((\"_obs\" in c))\n",
    "    and ((\"_mixed\" in c) is USE_MIXED_EFFECT)\n",
    "]\n",
    "assert len(y_labels) == 1\n",
    "\n",
    "print(x_labels)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsrv_std = 0.01\n",
    "n_ode_gru_dims = 10\n",
    "input_dim = 8\n",
    "output_dim = 1\n",
    "lr = 1e-2\n",
    "niters = 5000\n",
    "eps = 0.0005\n",
    "train_dict={}\n",
    "val_dict={}\n",
    "test_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = data.copy()\n",
    "data_norm = data_norm.dropna()\n",
    "N_train = random.sample(range(1,501), 400)\n",
    "N_train.sort()\n",
    "N_val =  [x for x in range(1,501) if x not in N_train]\n",
    "data_train = data_norm.loc[data_norm['individus'].isin(N_train)]\n",
    "data_val = data_norm[~data_norm['individus'].isin(N_train)]\n",
    "\n",
    "scaler_x = RobustScaler()\n",
    "data_train.loc[:,x_labels] = scaler_x.fit_transform(data_train[x_labels])\n",
    "data_val.loc[:,x_labels] = scaler_x.transform(data_val[x_labels ])\n",
    "\n",
    "scaler_y = RobustScaler()\n",
    "data_train.loc[:,y_labels] = scaler_y.fit_transform(data_train[y_labels])\n",
    "data_val.loc[:,y_labels] = scaler_y.transform(data_val[y_labels])\n",
    "\n",
    "groupby = data_train.groupby('individus')[x_labels].apply(np.array)\n",
    "input_train = [torch.Tensor(x) for x in groupby]\n",
    "input_train = torch.stack(input_train)\n",
    "groupby = data_train.groupby('individus')[y_labels].apply(np.array)\n",
    "target_train = [torch.Tensor(x) for x in groupby]\n",
    "target_train = torch.stack(target_train)\n",
    "\n",
    "groupby = data_val.groupby('individus')[x_labels].apply(np.array)\n",
    "input_val = [torch.Tensor(x) for x in groupby]\n",
    "input_val = torch.stack(input_val)\n",
    "groupby = data_val.groupby('individus')[y_labels].apply(np.array)\n",
    "target_val = [torch.Tensor(x) for x in groupby]\n",
    "target_val = torch.stack(target_val)\n",
    "\n",
    "groupby = data_train.groupby('individus')['temps'].apply(np.array)\n",
    "observed_tp= [torch.Tensor(x) for x in groupby]\n",
    "observed_tp = torch.stack(observed_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest_norm = dtest.copy()\n",
    "dtest_norm = dtest_norm.dropna()\n",
    "\n",
    "scaler_x_test = RobustScaler()\n",
    "dtest_norm.loc[:,x_labels] = scaler_x.fit_transform(dtest_norm[x_labels])\n",
    "\n",
    "scaler_y_test = RobustScaler()\n",
    "dtest_norm.loc[:,y_labels] = scaler_y.fit_transform(dtest_norm[y_labels])\n",
    "\n",
    "groupby = dtest_norm.groupby('individus')[x_labels].apply(np.array)\n",
    "input_test = [torch.Tensor(x) for x in groupby]\n",
    "input_test = torch.stack(input_test)\n",
    "groupby = dtest_norm.groupby('individus')[y_labels].apply(np.array)\n",
    "target_test = [torch.Tensor(x) for x in groupby]\n",
    "target_test = torch.stack(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict[\"tp_to_predict\"] = observed_tp[0] #The time point you want to make a prediction at, it only works at the observed time points\n",
    "train_dict[\"observed_data\"] = input_train #X\n",
    "train_dict[\"observed_tp\"] = observed_tp[0] #Time of observations\n",
    "train_dict[\"data_to_predict\"] = target_train #Y\n",
    "train_dict[\"mode\"] = None #interpolation or extrapolation, extrapolation isn't implemented\n",
    "train_dict['labels'] = None #Used for classification\n",
    "train_dict[\"observed_mask\"] =  torch.ones(input_train.shape) #matrix of the same size as inputs, 0 for the inputs you want to ignore, 1 for the others\n",
    "train_dict[\"mask_predicted_data\"] = torch.ones(target_train.shape) #same thing for the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict[\"tp_to_predict\"] = observed_tp[0] #The time point you want to make a prediction at, it only works at the observed time points\n",
    "val_dict[\"observed_data\"] = input_val #X\n",
    "val_dict[\"observed_tp\"] = observed_tp[0] #Time of observations\n",
    "val_dict[\"data_to_predict\"] = target_val #Y\n",
    "val_dict[\"mode\"] = None #interpolation or extrapolation, extrapolation isn't implemented\n",
    "val_dict['labels'] = None #Used for classification\n",
    "val_dict[\"observed_mask\"] =  torch.ones(input_val.shape) #matrix of the same size as inputs, 0 for the inputs you want to ignore, 1 for the others\n",
    "val_dict[\"mask_predicted_data\"] = torch.ones(target_val.shape) #same thing for the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The net used to represent the flucuation of h_t bewteen observations\n",
    "ode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims, \n",
    "    n_layers = 2, n_units = 25, nonlinear = nn.Tanh)\n",
    "\n",
    "rec_ode_func = ODEFunc(\n",
    "    input_dim = input_dim, \n",
    "    latent_dim = n_ode_gru_dims,\n",
    "    ode_func_net = ode_func_net,\n",
    "    device = device).to(device)\n",
    "\n",
    "#ODE solver\n",
    "z0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", 10, \n",
    "    odeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
    "\n",
    "model = ODE_RNN(input_dim, n_ode_gru_dims, output_dim, device = device, \n",
    "    z0_diffeq_solver = z0_diffeq_solver, n_gru_units = 25,\n",
    "    concat_mask = True, obsrv_std = obsrv_std,\n",
    "    use_binary_classif = False,\n",
    "    classif_per_tp = False,\n",
    "    n_labels = 1,\n",
    "    train_classif_w_reconstr =  False).to(device)\n",
    "\n",
    "optimizer = optim.Adamax(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val = [float('inf')]*100\n",
    "loss_train = []\n",
    "cur_loss_val = 0\n",
    "nb_epochs = 0\n",
    "min_loss = float('inf')\n",
    "criterion = nn.MSELoss()\n",
    "while abs(np.max(loss_val[-100:] - np.min(loss_val[-100:] + [cur_loss_val]))) >= eps and nb_epochs < niters:\n",
    "    optimizer.zero_grad()\n",
    "    utils.update_learning_rate(optimizer, decay_rate = 0.999, lowest = lr / 10)\n",
    "    train_res = model.compute_all_losses(train_dict, n_traj_samples = 100)\n",
    "    train_res[\"loss\"].backward()\n",
    "    loss_train.append(train_res['mse'].item())\n",
    "    optimizer.step()\n",
    "    y_val = model.get_reconstruction(time_steps_to_predict= val_dict['tp_to_predict'],\n",
    "                                     data= val_dict['observed_data'],\n",
    "                                     truth_time_steps= val_dict['observed_tp'],\n",
    "                                     mask =  val_dict['observed_mask'],\n",
    "                                     n_traj_samples=100)\n",
    "    a = torch.reshape(y_val[0], (100,26,1))\n",
    "    cur_loss_val = criterion(a, target_val).item()\n",
    "    loss_val.append(cur_loss_val)\n",
    "loss_val = loss_val[101:]\n",
    "#plot loss\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss_train, label =\"loss\")\n",
    "plt.plot(loss_val, label = \"validation\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../../../models/ODE-RNN/Résultats/\"+ \"Loss_TEST_\" + 'ODE RNN_' + RE + Time +\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.get_reconstruction(time_steps_to_predict= train_dict['tp_to_predict'],\n",
    "                                     data= train_dict['observed_data'],\n",
    "                                     truth_time_steps= train_dict['observed_tp'],\n",
    "                                     mask =  train_dict['observed_mask'],\n",
    "                                     n_traj_samples=400)\n",
    "y_pred = pred_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unscale data and aggregate training set\n",
    "multi_index = pd.MultiIndex.from_product([N_train, range(y_pred.shape[2])], names=['individus', 'temps'])\n",
    "df = pd.DataFrame(index = multi_index, data = y_pred.detach().numpy().flatten(), columns=['y_pred_ODE RNN_' + RE])\n",
    "df = df.reset_index()\n",
    "df = df.set_index(data_train.index)\n",
    "df.loc[:,'y_pred_ODE RNN_' + RE] = scaler_y.inverse_transform(df[['y_pred_ODE RNN_' + RE]])\n",
    "data_train.loc[:,y_labels] = scaler_y.inverse_transform(data_train[y_labels])\n",
    "\n",
    "multi_index = pd.MultiIndex.from_product([N_val, range(y_val[0].shape[2])], names=['individus', 'temps'])\n",
    "df_val = pd.DataFrame(index = multi_index, data = y_val[0].detach().numpy().flatten(), columns=['y_pred_ODE RNN_' + RE])\n",
    "df_val = df_val.reset_index()\n",
    "df_val = df_val.set_index(data_val.index)\n",
    "df_val.loc[:,'y_pred_ODE RNN_' + RE] = scaler_y.inverse_transform(df_val[['y_pred_ODE RNN_' + RE]])\n",
    "data_val.loc[:,y_labels] = scaler_y.inverse_transform(data_val[y_labels])\n",
    "\n",
    "df = pd.concat((df,df_val))\n",
    "data_train = pd.concat((data_train, data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "ex = np.random.choice(range(1,499), n)\n",
    "fig, axs = plt.subplots(n)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(50)\n",
    "for k in range(n):\n",
    "    axs[k].plot(data_train[(data_train['temps']!=0) & (data_train['individus']== ex[k])]['temps'],\n",
    "                data_train[(data_train['temps']!=0) & (data_train['individus']== ex[k])][y_labels], \n",
    "                label= 'target w/ noise')\n",
    "    axs[k].plot(data_train[(data_train['temps']!=0) & (data_train['individus']== ex[k])]['temps'],\n",
    "                data_train[(data_train['temps']!=0) & (data_train['individus']== ex[k])][y_labels[0][:-4]], \n",
    "                label= 'target')\n",
    "    axs[k].plot(df[(data_train['temps']!=0) & (df['individus']== ex[k])]['temps'],\n",
    "                df[(df['temps']!=0) & (df['individus']==ex[k])]['y_pred_' + 'ODE RNN' + '_' + RE], \n",
    "                label= 'prediction', linestyle='dashdot')\n",
    "    axs[k].legend()\n",
    "plt.savefig(\"../../../models/ODE-RNN/Résultats/\"+ \"TRAIN_\" + 'ODE RNN' + \"_\" + RE + Time + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MAE on train data:  0.29920316290528626\n",
      "mean MSE on train data:  0.231899992952095\n",
      "mean MAE on noised train data:  0.8662491051249261\n",
      "mean MSE on noised train data:  1.192696928719845\n"
     ]
    }
   ],
   "source": [
    "#Results on training\n",
    "MAE_list_train = []\n",
    "MSE_list_train = []\n",
    "MAE_list_train_obs = []\n",
    "MSE_list_train_obs = []\n",
    "for k in range(1,499):\n",
    "    pred_k = df[(df['temps']>5) & (df['individus'] == k)]['y_pred_' + 'ODE RNN' + '_' + RE]\n",
    "    target_k = data_train[(data_train['temps']>5) & (data_train['individus'] == k)][y_labels[0][:-4]]\n",
    "    target_k_obs = data_train[(data_train['temps']>5) & (data_train['individus'] == k)][y_labels]\n",
    "    MAE_list_train.append(MAE(pred_k, target_k))\n",
    "    MSE_list_train.append(MSE(pred_k, target_k))\n",
    "    MAE_list_train_obs.append(MAE(pred_k, target_k_obs))\n",
    "    MSE_list_train_obs.append(MSE(pred_k, target_k_obs))\n",
    "print(\"mean MAE on train data: \", np.mean(MAE_list_train))\n",
    "print(\"mean MSE on train data: \", np.mean(MSE_list_train))\n",
    "print(\"mean MAE on noised train data: \", np.mean(MAE_list_train_obs))\n",
    "print(\"mean MSE on noised train data: \", np.mean(MSE_list_train_obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict[\"tp_to_predict\"] = observed_tp[0]\n",
    "test_dict[\"observed_data\"] = input_test\n",
    "test_dict[\"observed_tp\"] = observed_tp[0]\n",
    "test_dict[\"data_to_predict\"] = target_test\n",
    "test_dict[\"mode\"] = None\n",
    "test_dict['labels'] = None\n",
    "test_dict[\"observed_mask\"] =  torch.ones(input_test.shape)\n",
    "test_dict[\"mask_predicted_data\"] = torch.ones(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = model.compute_all_losses(test_dict, n_traj_samples=500)\n",
    "print(test_res)\n",
    "print(test_res[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.get_reconstruction(time_steps_to_predict=test_dict['tp_to_predict'],\n",
    "                                     data=test_dict['observed_data'],\n",
    "                                     truth_time_steps=test_dict['observed_tp'],\n",
    "                                     mask = test_dict['observed_mask'],\n",
    "                                     n_traj_samples=500)\n",
    "y_test = pred_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index_test = pd.MultiIndex.from_product([range(y_test.shape[1]), range(y_test.shape[2])], names=['individus', 'temps'])\n",
    "df_test = pd.DataFrame(index = multi_index_test, data = y_test.detach().numpy().flatten(), columns=['y_test_' + 'ODE RNN' + '_' + RE])\n",
    "df_test = df_test.reset_index()\n",
    "df_test = df_test.set_index(dtest_norm.index)\n",
    "df_test['individus']+=1\n",
    "df_test.loc[:,'y_test_' + 'ODE RNN' + '_' + RE] = scaler_y.inverse_transform(df_test[['y_test_' + 'ODE RNN' + '_' + RE]])\n",
    "dtest_norm.loc[:,y_labels] = scaler_y.inverse_transform(dtest_norm[y_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "ex = randint(1,501, n)\n",
    "fig, axs = plt.subplots(n)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(50)\n",
    "for k in range(n):\n",
    "    axs[k].plot(dtest_norm.loc[(dtest_norm['temps']!=0) & (dtest_norm['individus']==ex[k])]['temps'], \n",
    "                dtest_norm.loc[(dtest_norm['temps']!=0) & (dtest_norm['individus']==ex[k])][y_labels], \n",
    "                label= 'target')\n",
    "    axs[k].plot(dtest_norm.loc[(dtest_norm['temps']!=0) & (dtest_norm['individus']==ex[k])]['temps'], \n",
    "                dtest_norm.loc[(dtest_norm['temps']!=0) & (dtest_norm['individus']==ex[k])][y_labels[0][:-4]], \n",
    "                label= 'target')\n",
    "    axs[k].plot(df_test.loc[(df_test['temps']!=0) & (df_test['individus']==ex[k])]['temps'],\n",
    "                df_test.loc[(df_test['temps']!=0) & (df_test['individus']==ex[k])]['y_test_' + 'ODE RNN' + '_' + RE], \n",
    "                label= 'prediction', linestyle='dotted')\n",
    "    axs[k].legend()\n",
    "plt.show()\n",
    "plt.savefig(\"../../../models/ODE-RNN/Résultats/\"+ \"TEST_\" + 'ODE RNN_' + RE + Time +\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scores on test data\n",
    "MAE_list_test = []\n",
    "MSE_list_test = []\n",
    "MAE_list_test_obs = []\n",
    "MSE_list_test_obs = []\n",
    "for k in range(1,501):\n",
    "    pred_k = df_test[(df_test['temps']>5) & (df_test['individus'] == k)]['y_test_' +'ODE RNN' + '_' + RE]\n",
    "    target_k = dtest_norm[(dtest_norm['temps']>5) & (dtest_norm['individus'] == k)][y_labels[0][:-4]]\n",
    "    target_k_obs = dtest_norm[(dtest_norm['temps']>5) & (dtest_norm['individus'] == k)][y_labels]\n",
    "    MAE_list_test.append(MAE(pred_k,target_k))\n",
    "    MSE_list_test.append(MSE(pred_k,target_k))\n",
    "    MAE_list_test_obs.append(MAE(pred_k,target_k_obs))\n",
    "    MSE_list_test_obs.append(MSE(pred_k,target_k_obs))\n",
    "print(\"mean MAE on test data: \", np.mean(MAE_list_test))\n",
    "print(\"mean MSE on test data: \", np.mean(MSE_list_test))\n",
    "print(\"mean MAE on noised test data: \", np.mean(MAE_list_test_obs))\n",
    "print(\"mean MSE on noised test data: \", np.mean(MSE_list_test_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../../models/ODE-RNN/Résultats/Prédictions_entrainement\" + 'ODE RNN' + \"_\" + RE + Time + \".csv\", index=False)\n",
    "df_test.to_csv(\"../../../models/ODE-RNN/Résultats/Prédictions_test\" + 'ODE RNN' + \"_\" + RE + Time + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([[RE, 'ODE RNN', niters, np.mean(MAE_list_train), np.mean(MSE_list_train), np.mean(MAE_list_train_obs), np.mean(MSE_list_train_obs), np.mean(MAE_list_test), np.mean(MSE_list_test), np.mean(MAE_list_test_obs), np.mean(MSE_list_test_obs)]], \n",
    "                       columns=['Random effect', 'Model', 'nb_epochs', \"MAE moyenne sur l'entrainement\", \"MSE moyenne sur l'entrainement\", \"MAE moyenne sur l'entrainement bruité\", \"MSE moyenne sur l'entrainement bruité\", \"MAE moyenne sur le test\", \"MSE moyenne sur le test\", \"MAE moyenne sur le test bruité\", \"MSE moyenne sur le test bruité\"])\n",
    "print(results)\n",
    "results = results.to_json(path_or_buf=\"../../../models/ODE-RNN/Résultats/\"+ 'ODE RNN' + \"_\" + RE + Time + \".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../../../models/ODE-RNN/Résultats/POIDS_\"+ 'ODE RNN' + \"_\" + RE + Time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
