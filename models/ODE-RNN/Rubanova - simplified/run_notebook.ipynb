{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent ODEs for Irregularly-Sampled Time Series\n",
    "#### Author: Yulia Rubanova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import pandas as pd\n",
    "from random import SystemRandom\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils\n",
    "from utils import compute_loss_all_batches\n",
    "\n",
    "from ode_rnn import *\n",
    "from ode_func import ODEFunc\n",
    "from diffeq_solver import DiffeqSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_NOISY_DATA = False\n",
    "USE_MIXED_EFFECT = False\n",
    "RANDOM_TIME = False\n",
    "RE = 'Mixed' if USE_MIXED_EFFECT else 'Fixed'\n",
    "Time = 'Random time' if RANDOM_TIME else 'Regular time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "CSV_FILE = \"../../../data/synthetic_bph_1/Simulations regular time/simulation1.csv\"\n",
    "CSV_Dtest = \"../../../data/synthetic_bph_1/Simulations regular time/01_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(CSV_FILE, sep=\";\", decimal=\",\")\n",
    "dtest = pd.read_csv(CSV_Dtest, sep=\";\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']\n",
      "['y_fixed_obs']\n"
     ]
    }
   ],
   "source": [
    "x_labels = [\n",
    "    c for c in data.columns if c.startswith(\"x\") and (((\"_\" in c) is USE_NOISY_DATA and ('obs' in c) is USE_NOISY_DATA))\n",
    "]\n",
    "if 'x8' not in x_labels:\n",
    "    x_labels.append('x8')\n",
    "#assert len(x_labels) == 8\n",
    "\n",
    "y_labels = [\n",
    "    c\n",
    "    for c in data.columns\n",
    "    if c.startswith(\"y\")\n",
    "    and ((\"_obs\" in c))\n",
    "    and ((\"_mixed\" in c) is USE_MIXED_EFFECT)\n",
    "]\n",
    "assert len(y_labels) == 1\n",
    "\n",
    "print(x_labels)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsrv_std = 0.01\n",
    "n_ode_gru_dims = 10\n",
    "input_dim = 8\n",
    "output_dim = 1\n",
    "lr = 1e-2\n",
    "niters = 5000\n",
    "train_dict={}\n",
    "test_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.copy()\n",
    "data_train = data_train.dropna()\n",
    "\n",
    "scaler_x = RobustScaler()\n",
    "data_train.loc[:,x_labels] = scaler_x.fit_transform(data_train[x_labels])\n",
    "\n",
    "scaler_y = RobustScaler()\n",
    "data_train.loc[:,y_labels] = scaler_y.fit_transform(data_train[y_labels])\n",
    "\n",
    "groupby = data_train.groupby('individus')[x_labels].apply(np.array)\n",
    "input_train = [torch.Tensor(x) for x in groupby]\n",
    "input_train = torch.stack(input_train)\n",
    "groupby = data_train.groupby('individus')[y_labels].apply(np.array)\n",
    "target_train = [torch.Tensor(x) for x in groupby]\n",
    "target_train = torch.stack(target_train)\n",
    "\n",
    "groupby = data_train.groupby('individus')['temps'].apply(np.array)\n",
    "observed_tp= [torch.Tensor(x) for x in groupby]\n",
    "observed_tp = torch.stack(observed_tp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest_norm = dtest.copy()\n",
    "dtest_norm = dtest_norm.dropna()\n",
    "\n",
    "scaler_x_test = RobustScaler()\n",
    "dtest_norm.loc[:,x_labels] = scaler_x.fit_transform(dtest_norm[x_labels])\n",
    "\n",
    "scaler_y_test = RobustScaler()\n",
    "dtest_norm.loc[:,y_labels] = scaler_y.fit_transform(dtest_norm[y_labels])\n",
    "\n",
    "groupby = dtest_norm.groupby('individus')[x_labels].apply(np.array)\n",
    "input_test = [torch.Tensor(x) for x in groupby]\n",
    "input_test = torch.stack(input_test)\n",
    "groupby = dtest_norm.groupby('individus')[y_labels].apply(np.array)\n",
    "target_test = [torch.Tensor(x) for x in groupby]\n",
    "target_test = torch.stack(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict[\"tp_to_predict\"] = observed_tp[0]\n",
    "train_dict[\"observed_data\"] = input_train\n",
    "train_dict[\"observed_tp\"] = observed_tp[0]\n",
    "train_dict[\"data_to_predict\"] = target_train\n",
    "train_dict[\"mode\"] = None\n",
    "train_dict['labels'] = None\n",
    "train_dict[\"observed_mask\"] =  torch.ones(input_train.shape)\n",
    "train_dict[\"mask_predicted_data\"] = torch.ones(target_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims, \n",
    "    n_layers = 2, n_units = 25, nonlinear = nn.Tanh)\n",
    "\n",
    "rec_ode_func = ODEFunc(\n",
    "    input_dim = input_dim, \n",
    "    latent_dim = n_ode_gru_dims,\n",
    "    ode_func_net = ode_func_net,\n",
    "    device = device).to(device)\n",
    "\n",
    "z0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", 10, \n",
    "    odeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
    "\n",
    "model = ODE_RNN(input_dim, n_ode_gru_dims, output_dim, device = device, \n",
    "    z0_diffeq_solver = z0_diffeq_solver, n_gru_units = 25,\n",
    "    concat_mask = True, obsrv_std = obsrv_std,\n",
    "    use_binary_classif = False,\n",
    "    classif_per_tp = False,\n",
    "    n_labels = 1,\n",
    "    train_classif_w_reconstr =  False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes less than 2mins for 100epochs, less than 9 for 500 epochs, 108 mins for 5000, 424mins pour 15000 epochs\n",
    "optimizer = optim.Adamax(model.parameters(), lr=lr)\n",
    "\n",
    "num_batches = 1\n",
    "loss_track = []\n",
    "for itr in range(1, num_batches * (niters + 1)):\n",
    "    optimizer.zero_grad()\n",
    "    utils.update_learning_rate(optimizer, decay_rate = 0.999, lowest = lr / 10)\n",
    "    train_res = model.compute_all_losses(train_dict, n_traj_samples = 500)\n",
    "    train_res[\"loss\"].backward()\n",
    "    loss_track.append(train_res['mse'].item())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss_track)\n",
    "plt.legend()\n",
    "plt.savefig(\"../../../models/ODE-RNN/Résultats/\"+ \"Loss_TEST_\" + 'ODE RNN_' + RE + Time +\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.get_reconstruction(time_steps_to_predict= train_dict['tp_to_predict'],\n",
    "                                     data= train_dict['observed_data'],\n",
    "                                     truth_time_steps= train_dict['observed_tp'],\n",
    "                                     mask =  train_dict['observed_mask'],\n",
    "                                     n_traj_samples=500)\n",
    "y_pred = pred_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unscale data and aggregate training set\n",
    "multi_index = pd.MultiIndex.from_product([range(1,y_pred.shape[1]+1), range(y_pred.shape[2])], names=['individus', 'temps'])\n",
    "df = pd.DataFrame(index = multi_index, data = y_pred.detach().numpy().flatten(), columns=['y_pred_' + 'ODE RNN' + '_' + RE])\n",
    "df = df.reset_index()\n",
    "df = df.set_index(data_train.index)\n",
    "df.loc[:,'y_pred_' + 'ODE RNN' + '_' + RE] = scaler_y.inverse_transform(df[['y_pred_' + 'ODE RNN' + '_' + RE]])\n",
    "data_train.loc[:,y_labels] = scaler_y.inverse_transform(data_train[y_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "ex = np.random.choice(range(1,499), n)\n",
    "fig, axs = plt.subplots(n)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(50)\n",
    "for k in range(n):\n",
    "    axs[k].plot(data_train[(data_train['temps']!=0) & (data_train['individus']== ex[k])]['temps'],\n",
    "                data_train[(data_train['temps']!=0) & (data_train['individus']== ex[k])][y_labels], \n",
    "                label= 'target w/ noise')\n",
    "    axs[k].plot(data_train[(data_train['temps']!=0) & (data_train['individus']== ex[k])]['temps'],\n",
    "                data_train[(data_train['temps']!=0) & (data_train['individus']== ex[k])][y_labels[0][:-4]], \n",
    "                label= 'target')\n",
    "    axs[k].plot(df[(data_train['temps']!=0) & (df['individus']== ex[k])]['temps'],\n",
    "                df[(df['temps']!=0) & (df['individus']==ex[k])]['y_pred_' + 'ODE RNN' + '_' + RE], \n",
    "                label= 'prediction', linestyle='dashdot')\n",
    "    axs[k].legend()\n",
    "plt.savefig(\"../../../models/ODE-RNN/Résultats/\"+ \"TRAIN_\" + 'ODE RNN' + \"_\" + RE + Time + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MAE on train data:  0.18953707825222915\n",
      "mean MSE on train data:  0.06605690683533985\n",
      "mean MAE on noised train data:  0.8093691973095476\n",
      "mean MSE on noised train data:  1.021037615521376\n"
     ]
    }
   ],
   "source": [
    "#Results on training\n",
    "MAE_list_train = []\n",
    "MSE_list_train = []\n",
    "MAE_list_train_obs = []\n",
    "MSE_list_train_obs = []\n",
    "for k in range(1,499):\n",
    "    pred_k = df[(df['temps']>5) & (df['individus'] == k)]['y_pred_' + 'ODE RNN' + '_' + RE]\n",
    "    target_k = data_train[(data_train['temps']>5) & (data_train['individus'] == k)][y_labels[0][:-4]]\n",
    "    target_k_obs = data_train[(data_train['temps']>5) & (data_train['individus'] == k)][y_labels]\n",
    "    MAE_list_train.append(MAE(pred_k, target_k))\n",
    "    MSE_list_train.append(MSE(pred_k, target_k))\n",
    "    MAE_list_train_obs.append(MAE(pred_k, target_k_obs))\n",
    "    MSE_list_train_obs.append(MSE(pred_k, target_k_obs))\n",
    "print(\"mean MAE on train data: \", np.mean(MAE_list_train))\n",
    "print(\"mean MSE on train data: \", np.mean(MSE_list_train))\n",
    "print(\"mean MAE on noised train data: \", np.mean(MAE_list_train_obs))\n",
    "print(\"mean MSE on noised train data: \", np.mean(MSE_list_train_obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict[\"tp_to_predict\"] = observed_tp[0]\n",
    "test_dict[\"observed_data\"] = input_test\n",
    "test_dict[\"observed_tp\"] = observed_tp[0]\n",
    "test_dict[\"data_to_predict\"] = target_test\n",
    "test_dict[\"mode\"] = None\n",
    "test_dict['labels'] = None\n",
    "test_dict[\"observed_mask\"] =  torch.ones(input_test.shape)\n",
    "test_dict[\"mask_predicted_data\"] = torch.ones(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(64.2015, grad_fn=<MeanBackward0>), 'likelihood': tensor(-64.2015), 'mse': tensor(0.0136), 'pois_likelihood': tensor(0.), 'ce_loss': tensor(0.), 'kl': 0.0, 'kl_first_p': 0.0, 'std_first_p': 0.0}\n",
      "tensor(64.2015, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_res = model.compute_all_losses(test_dict, n_traj_samples=500)\n",
    "print(test_res)\n",
    "print(test_res[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.get_reconstruction(time_steps_to_predict=test_dict['tp_to_predict'],\n",
    "                                     data=test_dict['observed_data'],\n",
    "                                     truth_time_steps=test_dict['observed_tp'],\n",
    "                                     mask = test_dict['observed_mask'],\n",
    "                                     n_traj_samples=500)\n",
    "y_test = pred_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index_test = pd.MultiIndex.from_product([range(y_test.shape[1]), range(y_test.shape[2])], names=['individus', 'temps'])\n",
    "df_test = pd.DataFrame(index = multi_index_test, data = y_test.detach().numpy().flatten(), columns=['y_test_' + 'ODE RNN' + '_' + RE])\n",
    "df_test = df_test.reset_index()\n",
    "df_test = df_test.set_index(dtest_norm.index)\n",
    "df_test['individus']+=1\n",
    "df_test.loc[:,'y_test_' + 'ODE RNN' + '_' + RE] = scaler_y.inverse_transform(df_test[['y_test_' + 'ODE RNN' + '_' + RE]])\n",
    "dtest_norm.loc[:,y_labels] = scaler_y.inverse_transform(dtest_norm[y_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_7360\\1708571498.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "ex = randint(1,501, n)\n",
    "fig, axs = plt.subplots(n)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(50)\n",
    "for k in range(n):\n",
    "    axs[k].plot(dtest_norm.loc[(dtest_norm['temps']!=0) & (dtest_norm['individus']==ex[k])]['temps'], \n",
    "                dtest_norm.loc[(dtest_norm['temps']!=0) & (dtest_norm['individus']==ex[k])][y_labels], \n",
    "                label= 'target')\n",
    "    axs[k].plot(dtest_norm.loc[(dtest_norm['temps']!=0) & (dtest_norm['individus']==ex[k])]['temps'], \n",
    "                dtest_norm.loc[(dtest_norm['temps']!=0) & (dtest_norm['individus']==ex[k])][y_labels[0][:-4]], \n",
    "                label= 'target')\n",
    "    axs[k].plot(df_test.loc[(df_test['temps']!=0) & (df_test['individus']==ex[k])]['temps'],\n",
    "                df_test.loc[(df_test['temps']!=0) & (df_test['individus']==ex[k])]['y_test_' + 'ODE RNN' + '_' + RE], \n",
    "                label= 'prediction', linestyle='dotted')\n",
    "    axs[k].legend()\n",
    "plt.show()\n",
    "plt.savefig(\"../../../models/ODE-RNN/Résultats/\"+ \"TEST_\" + 'ODE RNN_' + RE + Time +\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MAE on test data:  0.22918506588527288\n",
      "mean MSE on test data:  0.13520496165275134\n",
      "mean MAE on noised test data:  0.8362024016734649\n",
      "mean MSE on noised test data:  1.108727556092607\n"
     ]
    }
   ],
   "source": [
    "#Scores on test data\n",
    "MAE_list_test = []\n",
    "MSE_list_test = []\n",
    "MAE_list_test_obs = []\n",
    "MSE_list_test_obs = []\n",
    "for k in range(1,501):\n",
    "    pred_k = df_test[(df_test['temps']>5) & (df_test['individus'] == k)]['y_test_' +'ODE RNN' + '_' + RE]\n",
    "    target_k = dtest_norm[(dtest_norm['temps']>5) & (dtest_norm['individus'] == k)][y_labels[0][:-4]]\n",
    "    target_k_obs = dtest_norm[(dtest_norm['temps']>5) & (dtest_norm['individus'] == k)][y_labels]\n",
    "    MAE_list_test.append(MAE(pred_k,target_k))\n",
    "    MSE_list_test.append(MSE(pred_k,target_k))\n",
    "    MAE_list_test_obs.append(MAE(pred_k,target_k_obs))\n",
    "    MSE_list_test_obs.append(MSE(pred_k,target_k_obs))\n",
    "print(\"mean MAE on test data: \", np.mean(MAE_list_test))\n",
    "print(\"mean MSE on test data: \", np.mean(MSE_list_test))\n",
    "print(\"mean MAE on noised test data: \", np.mean(MAE_list_test_obs))\n",
    "print(\"mean MSE on noised test data: \", np.mean(MSE_list_test_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../../models/ODE-RNN/Résultats/Prédictions_entrainement\" + 'ODE RNN' + \"_\" + RE + Time + \".csv\", index=False)\n",
    "df_test.to_csv(\"../../../models/ODE-RNN/Résultats/Prédictions_test\" + 'ODE RNN' + \"_\" + RE + Time + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Random effect    Model  nb_epochs  MAE moyenne sur l'entrainement  \\\n",
      "0         Fixed  ODE RNN       5000                        0.189537   \n",
      "\n",
      "   MSE moyenne sur l'entrainement  MAE moyenne sur l'entrainement bruité  \\\n",
      "0                        0.066057                               0.809369   \n",
      "\n",
      "   MSE moyenne sur l'entrainement bruité  MAE moyenne sur le test  \\\n",
      "0                               1.021038                 0.229185   \n",
      "\n",
      "   MSE moyenne sur le test  MAE moyenne sur le test bruité  \\\n",
      "0                 0.135205                        0.836202   \n",
      "\n",
      "   MSE moyenne sur le test bruité  \n",
      "0                        1.108728  \n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame([[RE, 'ODE RNN', niters, np.mean(MAE_list_train), np.mean(MSE_list_train), np.mean(MAE_list_train_obs), np.mean(MSE_list_train_obs), np.mean(MAE_list_test), np.mean(MSE_list_test), np.mean(MAE_list_test_obs), np.mean(MSE_list_test_obs)]], \n",
    "                       columns=['Random effect', 'Model', 'nb_epochs', \"MAE moyenne sur l'entrainement\", \"MSE moyenne sur l'entrainement\", \"MAE moyenne sur l'entrainement bruité\", \"MSE moyenne sur l'entrainement bruité\", \"MAE moyenne sur le test\", \"MSE moyenne sur le test\", \"MAE moyenne sur le test bruité\", \"MSE moyenne sur le test bruité\"])\n",
    "print(results)\n",
    "results = results.to_json(path_or_buf=\"../../../models/ODE-RNN/Résultats/\"+ 'ODE RNN' + \"_\" + RE + Time + \".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../../../models/ODE-RNN/Résultats/POIDS_\"+ 'ODE RNN' + \"_\" + RE + Time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
